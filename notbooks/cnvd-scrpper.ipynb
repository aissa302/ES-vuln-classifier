{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import execjs\n",
    "import hashlib\n",
    "import json\n",
    "from requests.utils import add_dict_to_cookiejar\n",
    "\n",
    "\n",
    "def getCookie(data):\n",
    "    \"\"\"\n",
    "    通过加密对比得到正确cookie参数\n",
    "    :param data: 参数\n",
    "    :return: 返回正确cookie参数\n",
    "    \"\"\"\n",
    "    chars = len(data['chars'])\n",
    "    for i in range(chars):\n",
    "        for j in range(chars):\n",
    "            clearance = data['bts'][0] + data['chars'][i] + data['chars'][j] + data['bts'][1]\n",
    "            encrypt = None\n",
    "            if data['ha'] == 'md5':\n",
    "                encrypt = hashlib.md5()\n",
    "            elif data['ha'] == 'sha1':\n",
    "                encrypt = hashlib.sha1()\n",
    "            elif data['ha'] == 'sha256':\n",
    "                encrypt = hashlib.sha256()\n",
    "            encrypt.update(clearance.encode())\n",
    "            result = encrypt.hexdigest()\n",
    "            if result == data['ct']:\n",
    "                return clearance\n",
    "\n",
    "def setup_session(session, url, header):\n",
    "    # 使用session保持会话\n",
    "    res1 = session.get(url, headers=header)\n",
    "    jsl_clearance_s = re.findall(r'cookie=(.*?);location', res1.text)[0]\n",
    "    # 执行js代码\n",
    "    jsl_clearance_s = str(execjs.eval(jsl_clearance_s)).split('=')[1].split(';')[0]\n",
    "    # add_dict_to_cookiejar方法添加cookie\n",
    "    add_dict_to_cookiejar(session.cookies, {'__jsl_clearance_s': jsl_clearance_s})\n",
    "    res2 = session.get(url, headers=header)\n",
    "    # 提取go方法中的参数\n",
    "    data = json.loads(re.findall(r';go\\((.*?)\\)', res2.text)[0])\n",
    "    jsl_clearance_s = getCookie(data)\n",
    "    # 修改cookie\n",
    "    add_dict_to_cookiejar(session.cookies, {'__jsl_clearance_s': jsl_clearance_s})\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Initialize a session\n",
    "session = requests.Session()\n",
    "url = 'https://www.cnvd.org.cn/flaw/typeResult?typeId=33&max=100&offset=0'\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace sequences of whitespace characters with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Strip leading and trailing whitespace\n",
    "    return text.strip()\n",
    "\n",
    "def extract_data(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    data = {}\n",
    "\n",
    "    # Extracting and cleaning data\n",
    "    data['CNVD-ID'] = clean_text(soup.find(string='CNVD-ID').find_next().text)\n",
    "    data['CVE-ID'] = clean_text(soup.find(string='CVE ID').find_next().text)\n",
    "    data['Public Date'] = clean_text(soup.find(string='公开日期').find_next().text)\n",
    "    data['Harm Level'] = clean_text(soup.find(string='危害级别').find_next().text)\n",
    "    data['Affected Products'] = [clean_text(product) for product in soup.find(string='影响产品').find_next().stripped_strings]\n",
    "    data['Description'] = clean_text(soup.find(string='漏洞描述').find_next().text)\n",
    "    data['Vulnerability Type'] = clean_text(soup.find(string='漏洞类型').find_next().text)\n",
    "    data['Reference Link'] = clean_text(soup.find(string='参考链接').find_next().text)\n",
    "    data['Solution'] = clean_text(soup.find(string='漏洞解决方案').find_next().text)\n",
    "    data['Vendor Patch'] = clean_text(soup.find(string='厂商补丁').find_next().text)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def extract_links(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Find all 'a' tags with 'href' attributes containing '/flaw/show/CNVD-'\n",
    "    flaw_links = soup.find_all('a', href=lambda href: href and '/flaw/show/CNVD-' in href)\n",
    "\n",
    "    # Prepend the base URL to each link and store them in a list\n",
    "    base_url = \"https://www.cnvd.org.cn\"\n",
    "    full_links = [base_url + link['href'] for link in flaw_links]\n",
    "    return full_links\n",
    "\n",
    "def save_list_to_text_file(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for item in data:\n",
    "            file.write(f'{item}\\n')\n",
    "\n",
    "def file_to_list(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = file.readlines()\n",
    "        return [item.strip() for item in data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a working session\n",
    "session = setup_session(session, url, header)\n",
    "\n",
    "# Retrieve the links to the vulnerabilities\n",
    "cnvd_links = []\n",
    "for i in tqdm(range(0, 1500, 100), desc='Retrieving links', unit='pages'):\n",
    "    url = f'https://www.cnvd.org.cn/flaw/typeResult?typeId=33&max=100&offset={i}'\n",
    "    response = session.get(url, headers=header)\n",
    "    #print(response.text)\n",
    "    if response.status_code == 200:\n",
    "        #extracted_data = extract_data(response.text)\n",
    "        page_links = extract_links(response.text)\n",
    "        cnvd_links.extend(page_links)\n",
    "    else:\n",
    "        print(f'Failed to retrieve page {i//1500 + 1}')\n",
    "        break\n",
    "\n",
    "# Save the links to a text file\n",
    "save_list_to_text_file(cnvd_links, 'iot_cnvd_links.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from 1506 links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 0/1506 [00:00<?, ?links/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 1/1506 [00:05<2:14:32,  5.36s/links]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 2/1506 [00:10<2:14:31,  5.37s/links]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 3/1506 [00:16<2:14:28,  5.37s/links]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 4/1506 [00:21<2:15:20,  5.41s/links]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 5/1506 [01:26<11:16:11, 27.03s/links]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 6/1506 [01:32<8:11:36, 19.66s/links] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data:   0%|          | 7/1506 [01:38<5:49:53, 14.00s/links]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     21\u001b[0m         writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(file, fieldnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNVD-ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVE-ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPublic Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHarm Level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAffected Products\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVulnerability Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReference Link\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolution\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVendor Patch\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m, in \u001b[0;36mextract_data\u001b[0;34m(html)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Extracting and cleaning data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNVD-ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_text(soup\u001b[38;5;241m.\u001b[39mfind(string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNVD-ID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind_next()\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m---> 28\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVE-ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_text(\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCVE ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_next\u001b[49m()\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     29\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPublic Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_text(soup\u001b[38;5;241m.\u001b[39mfind(string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m公开日期\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind_next()\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     30\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHarm Level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_text(soup\u001b[38;5;241m.\u001b[39mfind(string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m危害级别\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind_next()\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_next'"
     ]
    }
   ],
   "source": [
    "# Retrieve the data from each link\n",
    "list_of_links = file_to_list('iot_cnvd_links.txt')\n",
    "print(f'Retrieving data from {len(list_of_links)} links')\n",
    "session.close()\n",
    "# Initialize CSV file and write the headers\n",
    "csv_file = 'cnvd-iot-vulnerabilities.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['CNVD-ID', 'CVE-ID', 'Public Date', 'Harm Level', 'Affected Products', 'Description', 'Vulnerability Type', 'Reference Link', 'Solution', 'Vendor Patch'])\n",
    "    writer.writeheader()\n",
    "\n",
    "session = setup_session(session, url, header)\n",
    "\n",
    "for link in tqdm(list_of_links, desc='Retrieving data', unit='links'):\n",
    "    if (list_of_links.index(link) + 1) % 5 == 0:\n",
    "        time.sleep(60)\n",
    "    response = session.get(link, headers=header)\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        extracted_data = extract_data(response.text)\n",
    "        with open(csv_file, 'a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=['CNVD-ID', 'CVE-ID', 'Public Date', 'Harm Level', 'Affected Products', 'Description', 'Vulnerability Type', 'Reference Link', 'Solution', 'Vendor Patch'])\n",
    "            writer.writerow(extracted_data)\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        print(f'Failed to retrieve data from {link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Write the extracted data to the CSV file\n",
    "        with open(csv_file, 'a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=['CNVD-ID', 'CVE-ID', 'Public Date', 'Harm Level', 'Affected Products', 'Description', 'Vulnerability Type', 'Reference Link', 'Solution', 'Vendor Patch'])\n",
    "            writer.writerow(extracted_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
